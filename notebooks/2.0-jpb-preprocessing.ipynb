{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_data = pd.read_csv('lending_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean features\n",
    "def remove_percentage_sign(df, feat):\n",
    "    df = df.copy()\n",
    "    df[feat] = df[feat].str.replace(r'%', '').astype('float')\n",
    "    return df\n",
    "\n",
    "for feat in ['int_rate', 'revol_util']:\n",
    "    lending_data = remove_percentage_sign(lending_data, feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_train, lending_val, rate_train, rate_val = train_test_split(\n",
    "    lending_data, lending_data['int_rate'], test_size=0.1, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "### High Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feats_with_na_above_thresh(df, min_thresh, max_thresh=1.0):\n",
    "    missing_feats = [feat for feat in df.columns if \n",
    "                     (df[feat].isnull().sum() / df.shape[0]) > min_thresh and\n",
    "                     df[feat].isnull().sum() / df.shape[0] <= max_thresh]\n",
    "    return df[missing_feats].isnull().mean().sort_values(ascending=False)\n",
    "\n",
    "high_perc_feats = feats_with_na_above_thresh(lending_train, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features that have > 90% missing in training data\n",
    "lending_train = lending_train.drop(high_perc_feats.index, axis=1)\n",
    "lending_val = lending_val.drop(high_perc_feats.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                    0.000015\n",
       "emp_title               0.073038\n",
       "emp_length              0.071984\n",
       "home_ownership          0.000015\n",
       "verification_status     0.000015\n",
       "issue_d                 0.000015\n",
       "pymnt_plan              0.000015\n",
       "purpose                 0.000015\n",
       "title                   0.000015\n",
       "zip_code                0.000018\n",
       "addr_state              0.000015\n",
       "earliest_cr_line        0.000015\n",
       "initial_list_status     0.000015\n",
       "application_type        0.000015\n",
       "hardship_flag           0.000015\n",
       "disbursement_method     0.000015\n",
       "debt_settlement_flag    0.000015\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats_with_na = [\n",
    "    feat for feat in lending_train.columns if lending_train[feat].isnull().sum() > 0 and\n",
    "        lending_train[feat].dtypes == 'O'\n",
    "]\n",
    "\n",
    "lending_train[cat_feats_with_na].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new label 'Missing' for the 2 features that have 7% missing\n",
    "lending_train[['emp_title', 'emp_length']] = lending_train[\n",
    "    ['emp_title', 'emp_length']].fillna('Missing')\n",
    "lending_val[['emp_title', 'emp_length']] = lending_val[\n",
    "    ['emp_title', 'emp_length']].fillna('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats_with_small_na = [\n",
    "    feat for feat in cat_feats_with_na if lending_train[feat].isnull().sum() > 0\n",
    "]\n",
    "\n",
    "# drop data points w/ very little missing\n",
    "lending_train = lending_train.dropna(subset=cat_feats_with_small_na)\n",
    "lending_val = lending_val.dropna(subset=cat_feats_with_small_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print([feat for feat in cat_feats_with_na if lending_train[feat].isnull().sum() > 0])\n",
    "print([feat for feat in cat_feats_with_na if lending_val[feat].isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dti                               0.001185\n",
       "mths_since_last_delinq            0.502441\n",
       "mths_since_last_record            0.828173\n",
       "revol_util                        0.001007\n",
       "mths_since_last_major_derog       0.732797\n",
       "mths_since_rcnt_il                0.029570\n",
       "il_util                           0.139429\n",
       "all_util                          0.000150\n",
       "avg_cur_bal                       0.000038\n",
       "bc_open_to_buy                    0.013058\n",
       "bc_util                           0.013504\n",
       "mo_sin_old_il_acct                0.029570\n",
       "mths_since_recent_bc              0.012354\n",
       "mths_since_recent_bc_dlq          0.768434\n",
       "mths_since_recent_inq             0.117419\n",
       "mths_since_recent_revol_delinq    0.664013\n",
       "num_tl_120dpd_2m                  0.050265\n",
       "percent_bc_gt_75                  0.013085\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_feats_with_na = [\n",
    "    feat for feat in lending_train.columns if lending_train[feat].isnull().sum() > 0 and\n",
    "        lending_train[feat].dtypes != 'O'\n",
    "]\n",
    "\n",
    "lending_train[num_feats_with_na].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With features that have greater than 5% of instances missing, we will create a binary missing value indicator variable, and replace the missing values in original variable with the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in [\n",
    "    'mths_since_last_delinq', 'mths_since_last_record', 'mths_since_last_major_derog',\n",
    "    'il_util', 'mths_since_recent_bc_dlq', 'mths_since_recent_inq', \n",
    "    'mths_since_recent_revol_delinq', 'num_tl_120dpd_2m']:\n",
    "    median_val = lending_train[feat].median()\n",
    "    lending_train[feat+'_na'] = np.where(lending_train[feat].isnull(), 1, 0)\n",
    "    lending_val[feat+'_na'] = np.where(lending_val[feat].isnull(), 1, 0)\n",
    "    lending_train[feat] = lending_train[feat].fillna(median_val)\n",
    "    lending_val[feat] = lending_val[feat].fillna(median_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the remaining instances\n",
    "num_feats_with_small_na = [\n",
    "    feat for feat in num_feats_with_na if lending_train[feat].isnull().sum() > 0\n",
    "]\n",
    "\n",
    "lending_train = lending_train.dropna(subset=num_feats_with_small_na)\n",
    "lending_val = lending_val.dropna(subset=num_feats_with_small_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print([feat for feat in num_feats_with_na if lending_train[feat].isnull().sum() > 0])\n",
    "print([feat for feat in num_feats_with_na if lending_val[feat].isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables\n",
    "\n",
    "### Nonpredictive Variables\n",
    "\n",
    "We will remove features that did not show any relationship with interest rates from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pred_cat_feats = [\n",
    "    'emp_title', 'emp_length', 'issue_d', 'purpose', 'title', 'addr_state',\n",
    "    'initial_list_status', 'zip_code', 'earliest_cr_line'\n",
    "]\n",
    "\n",
    "lending_train.drop(non_pred_cat_feats, axis=1, inplace=True)\n",
    "lending_val.drop(non_pred_cat_feats, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = [\n",
    "    feat for feat in lending_train.columns \n",
    "    if lending_train[feat].dtype == 'O'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rare Labels\n",
    "\n",
    "We will replace all values of categorical variables that account for less than 1% of loans with 'Rare'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'emp_title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bd38b806e1ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_feats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfreq_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_freq_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlending_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'int_rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     lending_train[feat] = np.where(lending_train[feat].isin(\n\u001b[1;32m      9\u001b[0m         freq_labels), lending_train[feat], 'Rare')\n",
      "\u001b[0;32m<ipython-input-17-bd38b806e1ee>\u001b[0m in \u001b[0;36mget_freq_labels\u001b[0;34m(df, feat, tgt, rare_thresh)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_freq_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrare_thresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcat_perc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcat_perc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcat_perc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrare_thresh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deploy-rates/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5808\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5809\u001b[0m             \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5810\u001b[0;31m             \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5811\u001b[0m         )\n\u001b[1;32m   5812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deploy-rates/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                 \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mmutated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmutated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m             )\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deploy-rates/lib/python3.7/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# Add key to exclusions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'emp_title'"
     ]
    }
   ],
   "source": [
    "def get_freq_labels(df, feat, tgt, rare_thresh):\n",
    "    df = df.copy()\n",
    "    cat_perc = df.groupby(feat)[tgt].count() / df.shape[0]\n",
    "    return cat_perc[cat_perc > rare_thresh].index\n",
    "\n",
    "for feat in cat_feats:\n",
    "    freq_labels = get_freq_labels(lending_train, feat, 'int_rate', 0.01)\n",
    "    lending_train[feat] = np.where(lending_train[feat].isin(\n",
    "        freq_labels), lending_train[feat], 'Rare')\n",
    "    lending_val[feat] = np.where(lending_val[feat].isin(\n",
    "        freq_labels), lending_val[feat], 'Rare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# sanity checks\n",
    "print([feat for feat in lending_train.columns if lending_train[feat].isnull().sum() > 0])\n",
    "print([feat for feat in lending_val.columns if lending_val[feat].isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lending_train = pd.get_dummies(lending_train)\n",
    "lending_val = pd.get_dummies(lending_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(381727, 104)\n",
      "(42453, 104)\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "print(lending_train.shape)\n",
    "print(lending_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned & processed dataframes\n",
    "lending_train.to_csv('lending_train.csv', index=False)\n",
    "lending_val.to_csv('lending_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
